<!doctype html><html lang=en-US><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://harshavardhan98.github.io/images/favicon.png><title>I know what my JVM did last Release? | பிரதிபலிப்பு - Reflections</title><meta name=title content="I know what my JVM did last Release?"><meta name=description content="A deep dive into the JVM metrics that actually matter after a release — and how to read them like a detective."><meta name=keywords content="observability,JVM,"><meta property="og:url" content="https://harshavardhan98.github.io/i-know-what-my-jvm-did-last-release/"><meta property="og:site_name" content="பிரதிபலிப்பு - Reflections"><meta property="og:title" content="I know what my JVM did last Release?"><meta property="og:description" content="A deep dive into the JVM metrics that actually matter after a release — and how to read them like a detective."><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-01-15T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-15T00:00:00+00:00"><meta property="article:tag" content="Observability"><meta property="article:tag" content="JVM"><meta property="og:image" content="https://harshavardhan98.github.io/images/share.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://harshavardhan98.github.io/images/share.png"><meta name=twitter:title content="I know what my JVM did last Release?"><meta name=twitter:description content="A deep dive into the JVM metrics that actually matter after a release — and how to read them like a detective."><meta itemprop=name content="I know what my JVM did last Release?"><meta itemprop=description content="A deep dive into the JVM metrics that actually matter after a release — and how to read them like a detective."><meta itemprop=datePublished content="2025-01-15T00:00:00+00:00"><meta itemprop=dateModified content="2025-01-15T00:00:00+00:00"><meta itemprop=wordCount content="1300"><meta itemprop=image content="https://harshavardhan98.github.io/images/share.png"><meta itemprop=keywords content="Observability,JVM"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style></head><body><header><a href=/ class=title><h2>பிரதிபலிப்பு - Reflections</h2></a><nav><a href=/>Home</a>
<a href=/blog>Blog</a></nav></header><main><h1>I know what my JVM did last Release?</h1><p><i><time datetime=2025-01-15 pubdate>15 Jan, 2025</time></i></p><content><p>It&rsquo;s 3 PM on a Friday and you plan to deploy the weekend change. You merged the PR, the pipeline is green and deployment is successful.
Everything looks fine until you receive a Slack message regarding &ldquo;API latency is a bit high and the customers are complaining?&rdquo;</p><p>You open your Grafana dashboard and you notice that the P99 lateny is slightly higher than usual but you are not sure what is the root cause. This post is a walk through of the JVM metrics you need to check and how to interpret them to find the root cause of the issue. I will try to provide an intuitive understanding of what &ldquo;normal&rdquo; graph shape looks like and what shapes on graph should make you nervous.
The metrics discussed in this post are the standard metrics exposed by the JVM prometheus exporter/OTEL agent.</p><h2 id=1-memory--garbage-collection>1. Memory & Garbage Collection</h2><p>This is where we need to start checking first. If the release introduced a memory leak, changed object allocation pattern, or accidentally upgraded a library which holds reference longer, it will show up here first</p><h3 id=heap-memory>Heap Memory:</h3><p>The JVM splits the heap into generations. The metric to look out for:</p><ul><li><strong>jvm_memory_used_bytes{area=&ldquo;heap&rdquo;}</strong> - This metric tells the total heap in use. Compare the baseline before and after the release. A slow upward trend that doesn&rsquo;t comeback down after GC is a classic memory leak shape.</li><li><strong>jvm_memory_used_bytes{area=&ldquo;Eden Space&rdquo;}</strong> - Eden space is the region where new objects are born. High churn here is normal. What we are looking for is where eden is filling up <em>faster</em> than before the release</li><li><strong>jvm_memory_used_bytes{area=&ldquo;Old Gen&rdquo;}</strong> - Old Gen contains objects that survived multiple GC cycles. If old gen is climbing steadily and not being reclaimed then this points to a leak or retention issue. This is the metric that pages you at 3 AM.</li><li><strong>jvm_memory_used_bytes{area=&ldquo;Survivor Space&rdquo;}</strong> - This is the waiting room between eden and old gen. If survivor space is consistently full, objects are being promoted to old gen too aggressively.</li></ul><h3 id=non-heap-memory>Non Heap Memory:</h3><p>Many In-Memory databases like Apache ignite uses off-heap memory for caching and storage. Libraries like Spring, ByteBuddy etc., which uses reflection and new class generation during run-time will lead to metaspace growth. Libraries like Netty and NIO libraries allocate direct buffer for performance which if not released properly can result in consuming all available native memory. High off-heap memory usage will catch us off-guard and it will affect other processes running in the host.</p><p><strong>jvm_memory_used_bytes{area=&ldquo;non_heap&rdquo;}</strong> - This metrics tells the space occupied by Metaspace, code cache, compressed class space. If this is growing unbounded, it indicates a clasloader leak common for hot-reload frameworks or libraries that heavily use reflection.</p><p><strong>jvm_memory_used_bytes{area=&ldquo;Metaspace&rdquo;}</strong> - Stores class metadata. A release that pulls in a fat new dependency or uses lot of dynamic proxies like Spring can cause metaspace to ballon. Metaspace doesn&rsquo;t have a fixed cap by default, so it can eat into system memory quietly.</p><p><strong>Garbage Collection Latency Measurement</strong>:
GC metrics tells how hard JVM is working to tame the memory</p><p>-<strong>Average GC duration</strong>: jvm_gc_pause_seconds_sum / jvm_gc_pause_seconds_count - total time spent in GC divided by the number of GC collections provides the average GC pause time. A sustained increase in average GC pause is a red-flag.</p><p>-<strong>Max GC Pause</strong>: This metric will provide the highest GC pause in the window. If this spikes from 50ms to 500ms, this will have a huge impact on the overall latency of the API</p><h3 id=promql-queries>PromQL Queries:</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-PromQL data-lang=PromQL><span style=display:flex><span><span style=color:#75715e># Old gen usage over time - look for upward-trending sawtooth</span>
</span></span><span style=display:flex><span>jvm_memory_used_bytes{id<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>Tenured Gen</span>&#34;} <span style=color:#f92672>/</span> jvm_memory_max_bytes{id<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>Tenured Gen</span>&#34;}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Average GC pause duration (5m window)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>rate</span><span style=color:#f92672>(</span>jvm_gc_pause_seconds_sum[<span style=color:#e6db74>5m</span>]<span style=color:#f92672>)</span> <span style=color:#f92672>/</span> <span style=color:#66d9ef>rate</span><span style=color:#f92672>(</span>jvm_gc_pause_seconds_count[<span style=color:#e6db74>5m</span>]<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># GC Frequency - number of collections per minute</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>rate</span><span style=color:#f92672>(</span>jvm_gc_pause_seconds_count[<span style=color:#e6db74>5m</span>]<span style=color:#f92672>)</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Heap Usage Ratio - set altert if above 85%</span>
</span></span><span style=display:flex><span>jvm_memory_used_bytes{area<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>heap</span>&#34;} <span style=color:#f92672>/</span> jvm_memory_max_bytes{area<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>heap</span>&#34;}
</span></span></code></pre></div><h3 id=good-references-for-understanding-jvm-gc-and-memory-monitoring>Good references for understanding JVM, GC and memory monitoring:</h3><p><a href=https://medium.com/@plumbr/memory-leaks-fallacies-and-misconce-8c79594a3986>Plumbr&rsquo;s blog on memory leak</a> <a href=https://blog.gceasy.io/interesting-garbage-collection-patterns/>Garbage Collection Patterns</a> <a href=https://www.uber.com/en-IN/blog/jvm-tuning-garbage-collection/>Uber JVM&rsquo;s memory tuning</a> <a href=https://www.datadoghq.com/blog/understanding-java-gc/>Datadog GC deep dive</a></p><h2 id=2-thread-metrics>2. Thread Metrics</h2><p>Thread metrics are the vital signs of your application&rsquo;s concurrency model. A release that introduces a blocking calls, lock contention issue or thread pool misconfiguration can be diagnozed using the below metrics.</p><p><strong>jvm_threads_live_threads</strong> - This metric gives the total active threads. If this jumps post-release and doesn&rsquo;t come back down, you are probably creating a lot of threads without proper shutdown</p><p><strong>jvm_threads_daemon_threads</strong> - Daemon threads die when the JVM exits. A sudden increase usually means a new background task or connection pool was introduced.</p><p><strong>jvm_threads_peak_threads</strong> - This metric provides the peak thread count since the JVM start. Helps us understand application&rsquo;s burst behaviour and capacity planning. If the value of the metrics is consistently close to a hard limit, it may indicate a need to adjust thread pool configurations.</p><p><strong>jvm_threads_states_threads</strong> - This metrics provides the number of threads which are in different states - RUNNABLE, BLOCKED, WAITING/TIMED_WAITING</p><p>RUNNABLE - number of threads which are actively doing work
BLOCKED - number of threads waiting to enter a synchronized block. If this is high, you have lock contention. A release that adds a synchronized keyword in ahot path can tank throughput
WAITING/TIMED_WAITING - number of threads waiting on I/O, sleep, or condition variables. Normal for thread pools sitting idle. Abnormal if the count is climbing - means threads are waiting and never coming back</p><h3 id=promql-queries-1>PromQL Queries:</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-PromQL data-lang=PromQL><span style=display:flex><span><span style=color:#75715e># BLOCKED thread count - should be near zero</span>
</span></span><span style=display:flex><span>jvm_threads_states_threads{state<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>blocked</span>&#34;}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Thread count growth rate - should be flat in steady state</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>deriv</span><span style=color:#f92672>(</span>jvm_threads_live_count[<span style=color:#e6db74>30m</span>]<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Ratio of BLOCKED to total threads - alert if &gt; 0.1</span>
</span></span><span style=display:flex><span>jvm_threads_states_threads{state<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>blocked</span>&#34;} <span style=color:#f92672>/</span> jvm_threads_live_threads
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Waiting threads - compared to baseline</span>
</span></span><span style=display:flex><span>jvm_threads_states_threads{state<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>waiting</span>&#34;} <span style=color:#f92672>+</span> jvm_threads_states_threads{state<span style=color:#f92672>=</span>&#34;<span style=color:#e6db74>timed-waiting</span>&#34;}
</span></span></code></pre></div><p><strong>Patterns to fear</strong>: BLOCKED thread goes from near zero to double digits. Throughput will be affected significantly even though CPU usage might be low when there is high thread contention.</p><h3 id=references-for-understanding-threads-and-its-states>References for understanding threads and its states</h3><p><a href=https://blog.fastthread.io/java-suspended-thread-states-blocked-waiting-timed_waiting/>Java Thread states</a> <a href=https://dzone.com/articles/how-analyze-java-thread-dumps>Java Thread Dump Analysis</a></p><h2 id=3-class-loading-metrics>3. Class loading metrics</h2><p>These metrics helps us to peek through runtime class creation by libraries/framework like Spring</p><p><strong>jvm_classes_loaded_classes</strong> - Number of classes currently loaded. Should stabilize after startup, if it keeps growing with traffic then it is possible some library is dynamically generating classes at runtime (reflection, proxies, scripting engines, groovy template)</p><p><strong>jvm_classes_unloadded_classes_total</strong> - This metrics tells the number of classes that were loaded and then garbade collected. If loaded classes grow but unloaded stays flat, the classloaded is holding references which means there is a class loader leak</p><h3 id=promql-queries-2>PromQL Queries:</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-PromQL data-lang=PromQL><span style=display:flex><span><span style=color:#75715e># Loaded class count - should plateau after startup</span>
</span></span><span style=display:flex><span>jvm_classes_loaded_classes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Class loading rate - should drop to approx 0 in steady state</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>rate</span><span style=color:#f92672>(</span>jvm_classes_loaded_classes[<span style=color:#e6db74>5m</span>]<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Classloader leak signal: loaded growing but unloaded flat</span>
</span></span><span style=display:flex><span>jvm_classes_loaded_classes <span style=color:#f92672>-</span> jvm_classes_unloaded_classes_total
</span></span></code></pre></div><p><strong>Patterns to fear</strong>: When we add a new dependency that does bytecode generation, uses dymaic proxies or custom classloading which are common with ORMs, serialization libraries etc, we need to keep track of these metrics when we introduce them</p><h2 id=4-jvm-compilation>4. JVM Compilation</h2><p>JVM will compile the hotpath bytecode to native code. This will take some time, so if we are comparing latency between the old and new release we should taking into consideration the time taken to warm up the JVM.</p><p>jvm_compilation_time_milliseconds_total - Cumulative time spent compiling, in the first few minutes after deploying the JVM, this metric will climb fast and latency might take a hit.</p><h3 id=promql-queries-3>PromQL Queries:</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-PromQL data-lang=PromQL><span style=display:flex><span><span style=color:#75715e># Compilation time rate - high during warmup, should drop to near-zero</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>rate</span><span style=color:#f92672>(</span>jvm_compilation_time_milliseconds_total[<span style=color:#e6db74>5m</span>]<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The below metric can be used to identify when warmup is &#34;done&#34; - the curve flattens</span>
</span></span><span style=display:flex><span>jvm_compilation_time_milliseconds_total
</span></span></code></pre></div><p><strong>Patterns to Fear</strong>
If the JVM takes a lot of time to warmup, we might need to start to intentionally warmup the JVM to cutdown the initial latency.</p><h3 id=references-for-jvm-warmup>References for JVM warmup</h3><p><a href=https://www.usenix.org/conference/osdi16/technical-sessions/presentation/lion>Usenix JVM warmup</a>
<a href=https://www.baeldung.com/java-jvm-warmup>Baeldung&rsquo;s JVM warmup</a>
<a href=https://tratt.net/laurie/blog/2022/more_evidence_for_problems_in_vm_warmup.html>Unpredicatability in JVM warmup</a></p><h2 id=gotchas>Gotchas:</h2><ul><li>JVM warmup</li><li>Interpretation of GC metrics in AOT based JVM like Graal JVM</li></ul><h2 id=references>References:</h2><ol><li><a href=https://copyconstruct.medium.com/monitoring-and-observability-8417d1952e1c>https://copyconstruct.medium.com/monitoring-and-observability-8417d1952e1c</a></li><li><a href=https://softwareengineeringdaily.com/2021/02/04/debunking-the-three-pillars-of-observability-myth/>https://softwareengineeringdaily.com/2021/02/04/debunking-the-three-pillars-of-observability-myth/</a></li><li><a href=https://thenewstack.io/observability-wont-replace-monitoring-because-it-shouldnt/>https://thenewstack.io/observability-wont-replace-monitoring-because-it-shouldnt/</a></li><li><a href=https://charity.wtf/category/observability/>https://charity.wtf/category/observability/</a></li></ol></content><p><a href=https://harshavardhan98.github.io/blog/observability/>#Observability</a>
<a href=https://harshavardhan98.github.io/blog/jvm/>#JVM</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>